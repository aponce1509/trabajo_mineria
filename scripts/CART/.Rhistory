AdultUCI[["fnlwgt"]] = NULL
AdultUCI[["education-num"]] = NULL
AdultUCI[[ "age"]] = ordered( cut ( AdultUCI[[ "age"]], c(15,25,45,65,100) ) ,
labels = c ("Young", "Middle-aged", "Senior", "Old"))
AdultUCI[[ "age"]] = ordered( cut ( AdultUCI[[ "age"]], c(15,25,45,65,100) ) ,
labels = c ("Young", "Middle-aged", "Senior", "Old"))
AdultUCI[[ "hours-per-week"]] = ordered( cut ( AdultUCI[[ "hours-per-week"]], c(0,25,40,60,168) ) ,
labels = c("Part-time", "Full-time", "Over-time", "Workaholic"))
AdultUCI[[ "capital-gain"]] = ordered( cut ( AdultUCI[[ "capital-gain"]], c(-Inf,0,median(AdultUCI[[
"capital-gain"]][AdultUCI[[ "capital-gain"]]>0]), Inf) ) , labels = c("None", "Low", "High"))
AdultUCI[[ "capital-loss"]] = ordered( cut ( AdultUCI[[ "capital-loss"]], c(-Inf,0, median(AdultUCI[[
"capital-loss"]][AdultUCI[[ "capital-loss"]]>0]), Inf) ) , labels = c("None", "Low", "High"))
Adult
Adult <- as(AdultUCI, "transactions")
Adult
summary(Adult)
data(“Epub”)
summary(Epub)
image(Epub)
data(“Epub”)
data("Epub”)
summary(Epub)
image(Epub)
data("Epub")
summary(Epub)
data("Epub")
summary(Epub)
image(Epub)
itemFrequencyPlot(Adult, support = 0.1, cex.names=0.8)
iAdult <- apriori(Adult, parameter = list(support = 0.1, target="frequent"))
iAdult <- sort(iAdult, by="support") # Los ordenamos por el valor del soporte
inspect(head(iAdult, n=10)) # Inspeccionamos los 10 primeros
size(iAdult)
inspect(iAdult[size(iAdult)==1])
barplot(table(size(iAdult)), xlab="itemset size", ylab="count")
size(iAdult)
inspect(iAdult[size(iAdult)==1])
imaxAdult <- iAdult[is.maximal(iAdult)]
inspect(head(sort(imaxAdult, by="support")))
icloAdult <- iAdult[is.closed(iAdult)]
inspect(head(sort(icloAdult, by="support")))
barplot( c(frequent=length(iAdult), closed=length(icloAdult),
maximal=length(imaxAdult)), ylab="count", xlab="itemsets")
rules <- apriori(Adult, parameter = list(support = 0.1, confidence = 0.8, minlen = 2))
summary(rules)
inspect(head(rules))
c
rulesSorted = sort(rules, by = "confidence")
inspect(head(rulesSorted))
rulesRaceWhite <- subset(rules, subset = lhs %in% "race=White" & lift > 1.2)
inspect(head(rulesRaceWhite))
redundant <- is.redundant(x = rulesSorted, measure = "confidence")
rulesPruned <- rulesSorted[!redundant] # remove redundant rules
rulesPruned
inspect(head(rulesPruned))
inspect(head(rulesPruned))
mInteres <- interestMeasure(rulesPruned, measure=c("hyperConfidence", "leverage"
,"phi", "gini"), transactions=Adult)
quality(rulesPruned) <- cbind(quality(rulesPruned), mInteres)
inspect(head(sort(rulesPruned, by="phi")))
install.packages("arulesViz")
library (arulesViz)
plot(rulesPruned)
plot(rulesPruned[1:6], method="graph")
plot(rulesPruned, method="grouped")
library(colorspace)
plot(rulesPruned[1:6], method="paracoord", reorder=TRUE,
control=list(col=sequential_hcl(100)))
write(rulesPruned, file="reglas.csv", sep = ",")
install.packages("pmml")
library(pmml)
write.PMML(rulesPruned, file="reglas.pmml")
reglasPMML = read.PMML("reglas.pmml")
setwd("~/")
california <- read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", sep="", na.strings="4")
View(california)
xtra<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
head(xtra)
require(kknn)
cali<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
attach(cali)
fitknn1 <- kknn(Y ~ ., cali, cali)
cali<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
names(xtra)[n+1] <-"Y"attach(cali)
require(kknn)
cali<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
n <-length(names(cali)) -1
names(cali)[1:n] <-paste ("X", 1:n, sep="")
names(cali)[n+1] <-"Y"
attach(cali)
require(kknn)
cali<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
n <-length(names(cali)) -1
names(cali)[1:n] <-paste ("X", 1:n, sep="")
names(cali)[n+1] <-"Y"
attach(cali)
View(cali)
fitknn1 <- kknn(Y ~ ., cali, cali)
plot(Y~X4)
points(X4,fitknn1$fitted.values,col="blue",pch=20)
names(fitknn1)
fitknn1
fitknn1
test_values <- fitknn1$fitted.values
head(test_values)
test_values <- fitknn1$fitted.values
head(test_values)
yprime = fitknn1$fitted.values
sqrt(sum((cali$Y-yprime)^2)/length(yprime))
fitknn2 <- kknn(Y ~ . -X7, cali, cali)
yprime = fitknn2$fitted.values; sqrt(sum((cali$Y-yprime)^2)/length(yprime)) #RMSE
fitknn2 <- kknn(Y ~ X1+ X2 + I(X5 * X6), cali, cali)
plot(Y~X4)
points(X4,fitknn1$fitted.values,col="blue",pch=20)
points(X4,fitknn2$fitted.values,col="red",pch=20)
fitknn3 <- kknn(Y ~ X1+ X2 + I(X5 * X6), cali, cali)
yprime = fitknn3$fitted.values
sqrt(sum((cali$Y-yprime)^2)/length(yprime)) #RMSE
fitprueba=lm(Y~X4 +X6 +I(X4 * X6) +I(X4^2) +I(X4^2 * X6),cali)
y_knn <- fitknn1$fitted.values
sqrt(sum((cali$Y - y_knn)^2) / length(y_knn))
y_lm <- fitprueba$fitted.values
sqrt(sum((cali$Y - y_lm)^2) / length(y_lm))
nombre <- "s"
run_lm_fold <- function(i, x = "california", tt = "test") {
file <- paste(x, "-5-", i, "tra.dat", sep="")
x_tra <- read.csv(file, comment.char="@", header=FALSE)
file <- paste(x, "-5-", i, "tst.dat", sep="")
x_tst <- read.csv(file, comment.char="@", header=FALSE)
In <- length(names(x_tra)) - 1
names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
names(x_tra)[In+1] <- "Y"
names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
names(x_tst)[In+1] <- "Y"
if (tt == "train") {
test <- x_tra
}
else {
test <- x_tst
}
fitMulti=lm(Y~.,x_tra)
yprime=predict(fitMulti,test)
sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train"))
lmMSEtest<-mean(sapply(1:5,run_lm_fold,nombre,"test"))
#------------- 5-fold cross-validation LM todas las variables
nombre <- "california"
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train"))
#------------- 5-fold cross-validation LM todas las variables
nombre <- "C:/Users/JORGE/Desktop/IntroCD/REGRESION/california"
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train"))
lmMSEtest<-mean(sapply(1:5,run_lm_fold,nombre,"test"))
#------------- 5-fold cross-validation KNN todas las variables
nombre <- "C:/Users/JORGE/Desktop/IntroCD/REGRESION/california"
run_knn_fold <- function(i, x, tt = "test") {
file <- paste(x, "-5-", i, "tra.dat", sep="")
x_tra <- read.csv(file, comment.char="@", header=FALSE)
file <- paste(x, "-5-", i, "tst.dat", sep="")
x_tst <- read.csv(file, comment.char="@", header=FALSE)
In <- length(names(x_tra)) - 1
names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
names(x_tra)[In+1] <- "Y"
names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
names(x_tst)[In+1] <- "Y"
if (tt == "train") {
test <- x_tra
}
else {
test <- x_tst
}
fitMulti=kknn(Y~.,x_tra,test)
yprime=fitMulti$fitted.values
sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
knnMSEtrain<-mean(sapply(1:5,run_knn_fold,nombre,"train"))
knnMSEtest<-mean(sapply(1:5,run_knn_fold,nombre,"test"))
resultados <- read.csv("regr_test_alumnos.csv")
tablatst <- cbind(resultados[,2:dim(resultados)[2]])
colnames(tablatst) <- names(resultados)[2:dim(resultados)[2]]
rownames(tablatst) <- resultados[,1]
lmMSEtrain
knnMSEtrain
lmMSEtest
knnMSEtest
reticulate::repl_python()
# %%
from os import accessy
from IPython.core.interactiveshell import InteractiveShell
from numpy import int64
reticulate::install_miniconda()
py_config()
reticulate::repl_python()
import os
import cv2
import numpy as np
library(tidyverse)
library(caret)
library(rpart)
set_train = as.data.frame(read_csv('training_set_featuresA.csv'))
set_labels = as.data.frame(read_csv('training_set_labels.csv'))
setwd("~/GitHub/TRABAJO/scripts/CART")
set_train = as.data.frame(read_csv('training_set_featuresA.csv'))
set_labels = as.data.frame(read_csv('training_set_labels.csv'))
train1_class1 = merge(set_train,set_labels[,c(1,2)])
train1_l1$respondent_id = NULL
train1_l1 = merge(set_train,set_labels[,c(1,2)])
train1_l1$respondent_id = NULL
train1_l1 = as.data.frame(lapply(train_l1,as.factor))
train_l1 = merge(set_train,set_labels[,c(1,2)])
train_l1$respondent_id = NULL
train_l1 = as.data.frame(lapply(train_l1,as.factor))
levels(dataTrain_class1$h1n1_vaccine) = c('No','Yes')
levels(train_l1$h1n1_vaccine) = c('No','Yes')
dtrain_l2 = merge(set_train,set_labels[,c(1,3)])
train_l2$respondent_id = NULL
dtrain_l2 = as.data.frame(lapply(dtrain_l2,as.factor))
train_l2 = merge(set_train,set_labels[,c(1,3)])
train_l2$respondent_id = NULL
dtrain_l2 = as.data.frame(lapply(dtrain_l2,as.factor))
train_l2 = as.data.frame(lapply(dtrain_l2,as.factor))
train_l2 = as.data.frame(lapply(train_l2,as.factor))
levels(dtrain_l2$seasonal_vaccine) = c('No','Yes')
Length = 5
# Siembro las semillas para que los resultados sean reproducibles. Preguntar a javi?¿?
set.seed(11)
# Creamos el modelo de tree
tree_cart = trainControl(method = "cv",
number = 5,
# paralelo true***
allowParallel = TRUE,
#seeds = seeds,
classProbs = T,
summaryFunction = twoClassSummary,
search='random')
#Lo del paralelo
library(parallel)
library(doParallel)
cluster = makeCluster(detectCores() - 1)
registerDoParallel(cluster)
# Desarrollamos el modelo. Al poner na.action=na.pass le estamos pasando los
# NAs al árbol, que sabe manejarlos (simplemente ignorando esa info)
set.seed(1)
tree_class1 = train(h1n1_vaccine~., data=dataTrain_class1, method='J48',
na.action = na.pass, trControl = treeControl,
metric = 'ROC', tuneLength=Length)
tree_class1 = train(h1n1_vaccine~., data=train_l1, method='RPART',
na.action = na.pass, trControl = treeControl,
metric = 'ROC', tuneLength=Length)
library(rpart)
# Desarrollamos el modelo. Al poner na.action=na.pass le estamos pasando los
# NAs al árbol, que sabe manejarlos (simplemente ignorando esa info)
set.seed(1)
tree_class1 = train(h1n1_vaccine~., data=train_l1, method='RPART',
na.action = na.pass, trControl = treeControl,
metric = 'ROC', tuneLength=Length)
tree_class2 = train(seasonal_vaccine~., data=train_l2, method='rpart',
na.action = na.pass, trControl = treeControl,
metric = 'ROC', tuneLength=Length)
tree_class1 = train(h1n1_vaccine~., data=train_l1, method='rpart',
na.action = na.pass, trControl = treeControl,
metric = 'ROC', tuneLength=Length)
tree_class1 = train(h1n1_vaccine~., data=train_l1, method='rpart',
na.action = na.pass, trControl = tree_cart,
metric = 'ROC', tuneLength=Length)
tree_l2 = train(seasonal_vaccine~., data=train_l2, method='rpart',
na.action = na.pass, trControl = tree_cart,
metric = 'ROC', tuneLength=Length)
levels(train_l2$seasonal_vaccine) = c('No','Yes')
train_l2 = merge(set_train,set_labels[,c(1,3)])
train_l2$respondent_id = NULL
train_l2 = as.data.frame(lapply(train_l2,as.factor))
levels(train_l2$seasonal_vaccine) = c('No','Yes')
# Extraemos la importancia de cada variable en los modelos construidos
varimp_class1 = varImp(tree_l1)
# Extraemos la importancia de cada variable en los modelos construidos
varimp_class1 = varImp(tree_l2)
tree_l2 = train(seasonal_vaccine~., data=train_l2, method='rpart',
na.action = na.pass, trControl = tree_cart,
metric = 'ROC', tuneLength=Length)
# Extraemos la importancia de cada variable en los modelos construidos
varimp_class1 = varImp(tree_l2)
varimp_class1 = varimp_class1$importance[1]
varimp_class1 = varimp_class1[order(varimp_class1$No,decreasing=T),,drop=F]
View(varimp_class1)
View(varimp_class1)
View(varimp_class1)
varimp_class1 = varimp_class1[order(varimp_class1$No,decreasing=T),,drop=F]
tree_l1 = train(h1n1_vaccine~., data=train_l1, method='rpart',
na.action = na.pass, trControl = tree_cart,
metric = 'ROC', tuneLength=Length)
# Terminamos la paralelización
stopCluster(cluster)
registerDoSEQ()
# Extraemos la importancia de cada variable en los modelos construidos
imp_l1 = varImp(tree_l1)
imp_l1 = varimp_class1$importance[1]
imp_l1 = varimp_class1[order(varimp_class1$No,decreasing=T),,drop=F]
imp_l1 = varimp_class1[order(imp_l1$No,decreasing=T),,drop=F]
imp_l1 = imp_l1$importance[1]
imp_l1 = imp_l1[order(imp_l1$No,decreasing=T),,drop=F]
imp_l1 = as.factor(imp_l1$importance[1])
imp_l1 = imp_l1[order(imp_l1$No,decreasing=T),,drop=F]
imp_l1
# Extraemos la importancia de cada variable en los modelos construidos
imp_l1 = varImp(tree_l1)
imp_l1 = imp_l1$importance[1]
imp_l1 = imp_l1[order(imp_l1$No,decreasing=T),,drop=F]
imp_l1
# Terminamos la paralelización
stopCluster(cluster)
registerDoSEQ()
seeds = vector(mode = "list", length = 11)
for(i in 1:10) seeds[[i]] = sample.int(n=1000, 5)
seeds[[11]] = sample.int(1000, 1)
# Creamos el modelo de tree
tree_cart = trainControl(method = "cv",
number = 5,
# paralelo true***
allowParallel = TRUE,
seeds = seeds,
classProbs = T,
summaryFunction = twoClassSummary,
search='random')
set.seed(1)
tree_l1 = train(h1n1_vaccine~., data=train_l1, method='rpart',
na.action = na.pass, trControl = tree_cart,
metric = 'ROC', tuneLength=Length)
#Lo del paralelo
library(parallel)
library(doParallel)
cluster = makeCluster(detectCores() - 1)
registerDoParallel(cluster)
set.seed(1)
tree_l1 = train(h1n1_vaccine~., data=train_l1, method='rpart',
na.action = na.pass, trControl = tree_cart,
metric = 'ROC', tuneLength=Length)
# Terminamos la paralelización
stopCluster(cluster)
registerDoSEQ()
# Importancia de las variables en los dos modelos
imp_l1 = varImp(tree_l1)
imp_l1 = imp_l1$importance[1]
imp_l1 = imp_l1[order(imp_l1$No,decreasing=T),,drop=F]
imp_l1
# Importancia de las variables en los dos modelos
imp_l1 = varImp(tree_l1)
View(imp_l1)
imp_l1 = imp_l1$importance[1]
View(imp_l1)
imp_l1 = imp_l1[order(imp_l1$Overall,decreasing=T),,drop=F]
imp_l1
# Importancia de las variables en los dos modelos
imp_l2 = varImp(tree_l2)
imp_l2 = imp_l2$importance[1]
imp_l2 = imp_l2[order(imp_l2$Overall,decreasing=T),,drop=F]
imp_l2
tree_l1
View(set_labels)
View(tree_l1)
out_l1 = predict(imp_l1, newdata = head(testing))
out_l1 = predict(tree_l1, newdata = head(testing))
out_l1 = predict(tree_l1)
confusionMatrix(train1_l1,out_l1)
levels(train_l1$h1n1_vaccine) = c('No','Yes')
confusionMatrix(train1_l1$h1n1_vaccine,out_l1)
train1_l1$h1n1_vaccine
train_l1 = merge(set_train,set_labels[,c(1,2)])
train_l1$respondent_id = NULL
train_l1 = as.data.frame(lapply(train_l1,as.factor))
levels(train_l1$h1n1_vaccine) = c('No','Yes')
confusionMatrix(train1_l1$h1n1_vaccine,out_l1)
out_l1 = predict(tree_l1)
out_l1
train1_l1$h1n1_vaccine
confusionMatrix(train1_l1$h1n1_vaccine,out_l1)
in_l1 = na.omit(train$h1n1_vaccine)
in_l1 = na.remove(train$h1n1_vaccine)
set_labels_c = drop_na(set_labels)
set_labels_c = drop_na(set_train)
out_l1 = predict(tree_l1)
len(out_l1)
length(out_l1)
train_l1_c = drop_na(train_l1)
View(train_l1_c)
in_l1 = (train$h1n1_vaccine)
confusionMatrix(train1_l1$h1n1_vaccine,out_l1)
levels(train_l2$seasonal_vaccine) = c('No','Yes')
in_l1 = (train$h1n1_vaccine)
in_l1 = (train_l1_c$h1n1_vaccine)
in_l1
levels(out_l1) = c('No','Yes')
confusionMatrix(train1_l1$h1n1_vaccine,out_l1)
in_l1
out_l1
levels(out_l1) = c('0','1')
out_l1
levels(in_l1) = c('0','1')
in_l1
confusionMatrix(train1_l1$h1n1_vaccine,out_l1)
confusionMatrix(in_l1,out_l1)
datos <- as.data.frame(read_csv('training_set_featuresA.csv'))
outlier_values <- boxplot.stats(datos)$out  # outlier values.
dat_lab <- as.data.frame(read_csv('training_set_labels.csv'))
df = merge(df_features,df_labels)
df$respondent_id = NULL
df = merge(datos,dat_lab)
df$respondent_id = NULL
View(df)
df$respondent_id = NULL
View(df)
df_encoded = df
df_encoded$sex = factor(df$sex, labels=c(0,1)) #Female 0,  #Male 1
df_encoded$marital_status = factor(df$marital_status, labels=c(0,1)) #Not Married 0, #Married 1
df_encoded$rent_or_own = factor(df$rent_or_own, labels=c(0,1)) #Own 0, #Rent 1
df_encoded$race = label_encoding(df$race)
df_encoded$employment_status = label_encoding(df$employment_status)
df_encoded$hhs_geo_region = label_encoding(df$hhs_geo_region)
df_encoded$census_msa = label_encoding(df$census_msa)
df_encoded$employment_industry = label_encoding(df$employment_industry)
df_encoded$rent_or_own = factor(df$rent_or_own, labels=c(0,1)) #Own 0, #Rent 1
df_encoded$race = label_encoding(df$race)
df_encoded$employment_status = label_encoding(df$employment_status)
df_encoded$education = factor(df$education, levels=c("< 12 Years", "12 Years", "Some College", "College Graduate"), labels=c(1:4), ordered=TRUE)
df_encoded$age_group = factor(df$age_group, levels=c("18 - 34 Years","35 - 44 Years","45 - 54 Years","55 - 64 Years","65+ Years"), labels=c(1:5), ordered=TRUE)
df_encoded$income_poverty = factor(df$income_poverty, levels=c("Below Poverty","<= $75,000, Above Poverty","> $75,000" ), labels=c(1:3), ordered=TRUE)
label_encoding = function(x){factor(x, labels=c(1:length(unique(na.omit(x)))))}
df_encoded$race = label_encoding(df$race)
df_encoded$employment_status = label_encoding(df$employment_status)
df_encoded$hhs_geo_region = label_encoding(df$hhs_geo_region)
df_encoded$census_msa = label_encoding(df$census_msa)
df_encoded$employment_industry = label_encoding(df$employment_industry)
df_encoded$employment_occupation = label_encoding(df$employment_occupation)
outlier_values <- boxplot.stats(df_encoded)$out  # outlier values.
View(df_encoded)
outlier_values <- boxplot.stats(df_encoded)$out  # outlier values.
outlier_values <- boxplot.stats(df_encoded[,c(1:4)])$out  # outlier values.
boxplot(data$pressure_height, main="Pressure Height", boxwex=0.1)
mod <- lm(df_encoded ~ ., data=df_encoded)
View(cluster)
mod <- lm(df_encoded ~ sex, data=df_encoded)
mod <- lm(df_encoded ~ ., data=df_encoded)
outlier_values <- boxplot.stats(df_encoded[,c(1:4)])$out  # outlier values.
View(datos)
outlier_values <- boxplot.stats(df_encoded[,c(1:22)])$out  # outlier values.
outlier_values <- boxplot.stats(df_encoded[,c(1:21)])$out  # outlier values.
outlier_values <- boxplot.stats(df_encoded[,c(1:20)])$out  # outlier values.
boxplot(df_encoded[,c(1:20)])
boxplot(df_encoded[,c(1:22)])
boxplot(df_encoded[,c(1:28)])
boxplot(df_encoded[,c(1:22)])
outlier_values <- boxplot.stats(df_encoded[,c(1:10)])$out  # outlier values.
outlier_values <- boxplot.stats(df_encoded[,c(1:15)])$out  # outlier values.
outlier_values <- boxplot.stats(df_encoded[,c(1:20)])$out  # outlier values.
outlier_values <- boxplot.stats(df_encoded[,c(1:19)])$out  # outlier values.
test.MVN = mvn(df_encoded, mvnTest = "energy")
#test normalidad multivariante
library(MNV)
library(MVN)
test.MVN = mvn(df_encoded, mvnTest = "energy")
test.MVN = mvn(df_encoded[,c(1:22)], mvnTest = "energy")
test.MVN = mvn(df_encoded[,c(1:19)], mvnTest = "energy")
View(df_encoded)
out_l1 = predict(tree_l1, na.action = na.pass)
#Sacamos el in y el output del conjunto train en factores para que confusionMatrix no proteste
length(out_l1)
levels(out_l1) = c('0','1')
confusionMatrix(in_l1,out_l1)
#Lo del paralelo
library(parallel)
library(doParallel)
cluster = makeCluster(detectCores() - 1)
registerDoParallel(cluster)
library(MVN)
test.MVN = mvn(df_encoded[,c(1:19)], mvnTest = "energy")
test.MVN$multivariateNormality["MVN"]
test.MVN = mvn(df_encoded[,c(1:6)], mvnTest = "energy")
test.MVN = mvn(set_labels_c[,c(1:3)], mvnTest = "energy")
test.MVN$multivariateNormality["MVN"]
test.MVN = mvn(df_encoded[,c(1:4)], mvnTest = "energy")
library(CerioliOutlierDetection)
cerioli2010.fsrmcd.test(train_l1_c[,c(1:2)])
cerioli2010.fsrmcd.test(as.matrix(train_l1_c[,c(1:2)]))
cerioli2010.fsrmcd.test(as.matrix(train_l1_c[,c(1:2)]))
as.matrix(train_l1_c[,c(1:2)])
cerioli2010.fsrmcd.test(as.matrix(as.integer(train_l1_c[,c(1:2)])))
cerioli2010.fsrmcd.test(as.matrix(as.integer(train_l1[,c(1:2)])))
source("~/GitHub/TRABAJO/scripts/CART/outliers.R", echo=TRUE)
cerioli2010.fsrmcd.test(as.matrix(train_l1_c[,c(1:2)]))
cerioli2010.fsrmcd.test(as.matrix(train_l1[,c(1:2)]))
set_train = as.data.frame(read_csv('training_set_featuresA.csv'))
set_train = drop_na(as.data.frame(read_csv('training_set_featuresA.csv')))
set_train = drop_na(set_train)
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:2)]))
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:19)]))
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:18)]))
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:10)]))
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:5)]))
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:3)]))
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:2)]))
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:3)]))
set.seed(2)
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:3)]))
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:4)]))
cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:2)]))
out <- cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:2)]))
out$outliers
out <- cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:2)]), signif.alpha = 0.0000077)
out$outliers
out <- cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:2)]), signif.alpha = 0.0000077)
out <- cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:5)]), signif.alpha = 0.0000077)
out <- cerioli2010.fsrmcd.test(as.matrix(set_train[,c(1:3)]), signif.alpha = 0.0000077)
