d5 = as.data.frame(cbind(y= as.numeric(I(train$y==5)), x1 =train$x1, x2 =train$x2))
d6 = as.data.frame(cbind(y= as.numeric(I(train$y==6)), x1 =train$x1, x2 =train$x2))
d7 = as.data.frame(cbind(y= as.numeric(I(train$y==7)), x1 =train$x1, x2 =train$x2))
d8 = as.data.frame(cbind(y= as.numeric(I(train$y==8)), x1 =train$x1, x2 =train$x2))
mRL1 <- glm(y ~ ns(x1,4) + ns(x2,4) , data = d1)
mRL2 <- glm(y ~ ns(x1,4) + ns(x2,4) , data = d2)
mRL3 <- glm(y ~ ns(x1,4) + ns(x2,4) , data = d3)
mRL4 <- glm(y ~ ns(x1,4) + ns(x2,4) , data = d4)
mRL5 <- glm(y ~ ns(x1,4) + ns(x2,4) , data = d5)
mRL6 <- glm(y ~ ns(x1,4) + ns(x2,4) , data = d6)
mRL7 <- glm(y ~ ns(x1,4) + ns(x2,4) , data = d7)
mRL8 <- glm(y ~ ns(x1,4) + ns(x2,4) , data = d8)
SmRL <- cbind (predict(mRL1, newdata = train, type="response"),
predict(mRL2, newdata = train, type="response"),
predict(mRL3, newdata = train, type="response"),
predict(mRL4, newdata = train, type="response"),
predict(mRL5, newdata = train, type="response"),
predict(mRL6, newdata = train, type="response"),
predict(mRL7, newdata = train, type="response"),
predict(mRL8, newdata = train, type="response"))
salida = sapply(1:nrow(SmRL), function(x) {which.max(SmRL[x,])})
Acierto(train$y,salida)
SmRLTest <- cbind (predict(mRL1, newdata = test, type="response"),
predict(mRL2, newdata = test, type="response"),
predict(mRL3, newdata = test, type="response"),
predict(mRL4, newdata = test, type="response"),
predict(mRL5, newdata = test, type="response"),
predict(mRL6, newdata = test, type="response"),
predict(mRL7, newdata = test, type="response"),
predict(mRL8, newdata = test, type="response"))
salidaTest = sapply(1:nrow(SmRLTest), function(x) {which.max(SmRLTest[x,])})
Acierto(test$y,salidaTest)
cla1 <- cbind(xz[,2],xz [,1])
cla1 <- cbind(xz[,2],xz[,1])
xz <- expand.grid( x2 = x.pred, x1 = z.pred)
# Pintado de espacios de decision
grid.lines = 200
x.pred <- seq(min(datos$x2), max(datos$x2), length.out = grid.lines)
z.pred <- seq(min(datos$x1), max(datos$x1), length.out = grid.lines)
xz <- expand.grid( x2 = x.pred, x1 = z.pred)
SmRLTotal <- cbind (predict(mRL1, newdata = xz, type="response"),
predict(mRL2, newdata = xz, type="response"),
predict(mRL3, newdata = xz, type="response"),
predict(mRL4, newdata = xz, type="response"),
predict(mRL5, newdata = xz, type="response"),
predict(mRL6, newdata = xz, type="response"),
predict(mRL7, newdata = xz, type="response"),
predict(mRL8, newdata = xz, type="response"))
salidaTotal1 = sapply(1:nrow(SmRLTotal), function(x) {which.max(SmRLTotal[x,])})
plot(xz[,2], xz[,1], col= salidaTotal1, pch='*')
points(datos$x1, datos$x2, col=datos$y, pch = "x")
cla1 <- cbind(xz[,2],xz[,1])
View(cla1)
cla1 <- rbind(xz[,2],xz[,1])
View(cla1)
xz[,2]
cla1 <- rbind(xz[,2],xz[,1])
cla1 <- cbind(xz[,2],xz[,1])
View(cla1)
library(tree)
train[,1] = as.factor(train[,1])
mT <- tree(y ~ x1 + x2 , data = train)
yprime =predict(mT, newdata = train,type="class")
# training
Acierto(train$y,yprime)
yprimeTest =predict(mT, newdata = test,type="class")
# test
Acierto(test$y,yprimeTest)
# Pintado de espacios de decision
x.pred <- seq(min(datos$x2), max(datos$x2), length.out = grid.lines)
z.pred <- seq(min(datos$x1), max(datos$x1), length.out = grid.lines)
xz <- expand.grid( x2 = x.pred, x1 = z.pred)
SmTtotal <-predict(mT, newdata = xz,type="class")
cla2 <- cbind(xz[,2],xz[,1])
common <- sapply(cla1, function(x){ x == cla2})
common <- which(cla1 == cla2)
View(cla1)
View(cla2)
common <- which(cla1 == cla2)
common <- which(cla1 == cla2 & cla2 == cla1)
# Pintado de espacios de decision
grid.lines = 200
x.pred <- seq(min(datos$x2), max(datos$x2), length.out = grid.lines)
z.pred <- seq(min(datos$x1), max(datos$x1), length.out = grid.lines)
xz <- expand.grid( x2 = x.pred, x1 = z.pred)
SmRLTotal <- cbind (predict(mRL1, newdata = xz, type="response"),
predict(mRL2, newdata = xz, type="response"),
predict(mRL3, newdata = xz, type="response"),
predict(mRL4, newdata = xz, type="response"),
predict(mRL5, newdata = xz, type="response"),
predict(mRL6, newdata = xz, type="response"),
predict(mRL7, newdata = xz, type="response"),
predict(mRL8, newdata = xz, type="response"))
salidaTotal1 = sapply(1:nrow(SmRLTotal), function(x) {which.max(SmRLTotal[x,])})
plot(xz[,2], xz[,1], col= salidaTotal1, pch='*')
points(datos$x1, datos$x2, col=datos$y, pch = "x")
cla1 <- cbind(xz[,2],xz[,1])
library(tree)
train[,1] = as.factor(train[,1])
mT <- tree(y ~ x1 + x2 , data = train)
yprime =predict(mT, newdata = train,type="class")
# training
Acierto(train$y,yprime)
yprimeTest =predict(mT, newdata = test,type="class")
# test
Acierto(test$y,yprimeTest)
# Pintado de espacios de decision
x.pred <- seq(min(datos$x2), max(datos$x2), length.out = grid.lines)
z.pred <- seq(min(datos$x1), max(datos$x1), length.out = grid.lines)
xz <- expand.grid( x2 = x.pred, x1 = z.pred)
SmTtotal <-predict(mT, newdata = xz,type="class")
plot(xz[,2], xz[,1], col= SmTtotal, pch='*')
points(datos$x1, datos$x2, col=datos$y, pch = "x")
cla2 <- cbind(xz[,2],xz[,1])
common <- which(cla1 == cla2 & cla2 == cla1)
View(SmRLTotal)
# Pintado de espacios de decision
x.pred <- seq(min(datos$x2), max(datos$x2), length.out = grid.lines)
z.pred <- seq(min(datos$x1), max(datos$x1), length.out = grid.lines)
xz <- expand.grid( x2 = x.pred, x1 = z.pred)
SmTtotal <-predict(mT, newdata = xz,type="class")
View(SmRLTotal)
cla2 <- cbind(xz[,2],xz[,1],max(SmTtotal))
cla2 <- cbind(xz[,2],xz[,1],(SmTtotal))
common <- which(cla1 == cla2 & cla1 == cla3)
salida = sapply(1:nrow(SmRL), function(x) {which.max(SmRL[x,])})
cla1 <- cbind(xz[,2],xz[,1],salida)
cla1 <- salida
cla1 <- salidaTotal1
SmTtotal <-predict(mT, newdata = xz,type="class")
cla2 <- (SmTtotal)
cla2 <- as.list(SmTtotal)
View(cla2)
cla2 <- (SmTtotal)
SmTtotal
cla2 <- as.array(SmTtotal)
cla2 <- as.integer(SmTtotal)
cla3 <- as.integer(SmTtotal)
cla2 <- as.integer(salidaTotal4)
library (gbm)
mB =gbm(y~x1+x2, data=train,
distribution="multinomial",n.trees =500,
interaction.depth =4)
SmB = predict (mB ,newdata = train, n.trees =500)
SmB = as.data.frame(SmB)
SmBT = sapply(1:nrow(SmB), function(x) {which.max(SmB[x,])})
SmBTes = predict (mB ,newdata = test, n.trees =500)
SmBTes = as.data.frame(SmBTes)
SmBTest = sapply(1:nrow(SmBTes), function(x) {which.max(SmBTes[x,])})
Acierto(train$y,SmBT)
Acierto(test$y,SmBTest)
plot(train$x1,train$x2,col=train$y,pch=0,
xlab = "Longitud", ylab = "Latitud", title("Provincias"))
points(train$x1,train$x2,col=SmBT,pch="x")
plot(test$x1,test$x2,col=test$y,pch=0,
xlab = "Longitud", ylab = "Latitud", title("Provincias"))
points(test$x1,test$x2,col=SmBTest,pch="x")
# Pintado de espacios de decision
grid.lines <- 100
x.pred <- seq(min(bd$longitud), max(bd$longitud), length.out = grid.lines)
z.pred <- seq(min(bd$latitud), max(bd$latitud), length.out = grid.lines)
xz <- expand.grid( x2 = x.pred, x1 = z.pred)
d <- predict(mB, newdata = xz, n.trees = 500)
d = as.data.frame(d)
salidaTotal4 = sapply(1:nrow(d), function(x) {which.max(d[x,])})
points(xz[,2], xz[,1], col = salidaTotal4, pch="*")
cla2 <- as.integer(salidaTotal4)
cla4 <- as.integer(salidaTotal4)
library(tree)
train[,1] = as.factor(train[,1])
mT <- tree(y ~ x1 + x2 , data = train)
yprime =predict(mT, newdata = train,type="class")
# Pintado del resultado
# training
Acierto(train$y,yprime)
yprimeTest =predict(mT, newdata = test,type="class")
# test
Acierto(test$y,yprimeTest)
# Pintado de espacios de decision
x.pred <- seq(min(datos$x2), max(datos$x2), length.out = grid.lines)
z.pred <- seq(min(datos$x1), max(datos$x1), length.out = grid.lines)
xz <- expand.grid( x2 = x.pred, x1 = z.pred)
SmTtotal <-predict(mT, newdata = xz,type="class")
plot(xz[,2], xz[,1], col= SmTtotal, pch='*')
points(datos$x1, datos$x2, col=datos$y, pch = "x")
cla2 <- as.integer(SmTtotal)
common <- which(cla1 == cla2 == cla3 == cla4)
common <- which(((cla1 == cla2) == cla3) == cla4)
common <- cla1[which(((cla1 == cla2) == cla3) == cla4)]
points(xz[,2], xz[,1], col = salidaTotal4, pch="*")
points(xz[,2], xz[,1], col = salidaTotal4, pch="*")
plot(xz[,2], xz[,1], col= SmTtotal, pch='*')
points(datos$x1, datos$x2, col=datos$y, pch = "x")
plot(xz[,2], xz[,1], col= common, pch='*')
common
common[2000:2100]
common <- cla1[which(((cla1 == cla2) == cla3) == cla4)]
common[2000:2100]
levels(common)
as.factor(common)
common <- cla1[which(cla1 == cla2 & cla1 == cla3 &cla1 == cla4)]
as.factor(common)
common <- [which(cla1 == cla2 & cla1 == cla3 &cla1 == cla4)]
common <- which(cla1 == cla2 & cla1 == cla3 & cla1 == cla4)
as.factor(common)
common <- cla1[which(cla1 == cla2 & cla1 == cla3 & cla1 == cla4)]
common[200:210]
common
common <- cla1[which(cla1 == cla2 && cla1 == cla3 & cla1 == cla4)]
common <- cla1[which(cla1 == cla2 && cla1 == cla3 && cla1 == cla4)]
common <- cla1[which(cla1 == cla2 & cla1 == cla3 & cla1 == cla4)]
common <- cla1[which(cla1 == cla2)]
#& cla1 == cla3 & cla1 == cla4)]
common
as.factor(common)
plot(xz[,2], xz[,1], col= common, pch='*')
common <- cla1[ifelse(cla1 == cla2,TRUE,FALSE)]
#& cla1 == cla3 & cla1 == cla4)]
common
plot(xz[,2], xz[,1], col= common, pch='*')
install.packages("arules")
library(arules)
data()
AdultUCI
?AdultUCI
?Groceries
AdultUCI <- AdultUCI
AdultUCI <- AdultUCI
library(arules)
AdultUCI <- AdultUCI
library(arules)
?AdultUCI
dat <- AdultUCI
data("AdultUCI")
dim(AdultUCI) ## Consultamos sus dimensiones
AdultUCI[1:2,] ## Vemos las 2 primeras filas para ver los atributos sus tipos
AdultUCI[["fnlwgt"]] = NULL
AdultUCI[["education-num"]] = NULL
AdultUCI[[ "age"]] = ordered( cut ( AdultUCI[[ "age"]], c(15,25,45,65,100) ) ,
labels = c ("Young", "Middle-aged", "Senior", "Old"))
AdultUCI[[ "age"]] = ordered( cut ( AdultUCI[[ "age"]], c(15,25,45,65,100) ) ,
labels = c ("Young", "Middle-aged", "Senior", "Old"))
AdultUCI[[ "hours-per-week"]] = ordered( cut ( AdultUCI[[ "hours-per-week"]], c(0,25,40,60,168) ) ,
labels = c("Part-time", "Full-time", "Over-time", "Workaholic"))
AdultUCI[[ "capital-gain"]] = ordered( cut ( AdultUCI[[ "capital-gain"]], c(-Inf,0,median(AdultUCI[[
"capital-gain"]][AdultUCI[[ "capital-gain"]]>0]), Inf) ) , labels = c("None", "Low", "High"))
AdultUCI[[ "capital-loss"]] = ordered( cut ( AdultUCI[[ "capital-loss"]], c(-Inf,0, median(AdultUCI[[
"capital-loss"]][AdultUCI[[ "capital-loss"]]>0]), Inf) ) , labels = c("None", "Low", "High"))
Adult
Adult <- as(AdultUCI, "transactions")
Adult
summary(Adult)
data(“Epub”)
summary(Epub)
image(Epub)
data(“Epub”)
data("Epub”)
summary(Epub)
image(Epub)
data("Epub")
summary(Epub)
data("Epub")
summary(Epub)
image(Epub)
itemFrequencyPlot(Adult, support = 0.1, cex.names=0.8)
iAdult <- apriori(Adult, parameter = list(support = 0.1, target="frequent"))
iAdult <- sort(iAdult, by="support") # Los ordenamos por el valor del soporte
inspect(head(iAdult, n=10)) # Inspeccionamos los 10 primeros
size(iAdult)
inspect(iAdult[size(iAdult)==1])
barplot(table(size(iAdult)), xlab="itemset size", ylab="count")
size(iAdult)
inspect(iAdult[size(iAdult)==1])
imaxAdult <- iAdult[is.maximal(iAdult)]
inspect(head(sort(imaxAdult, by="support")))
icloAdult <- iAdult[is.closed(iAdult)]
inspect(head(sort(icloAdult, by="support")))
barplot( c(frequent=length(iAdult), closed=length(icloAdult),
maximal=length(imaxAdult)), ylab="count", xlab="itemsets")
rules <- apriori(Adult, parameter = list(support = 0.1, confidence = 0.8, minlen = 2))
summary(rules)
inspect(head(rules))
c
rulesSorted = sort(rules, by = "confidence")
inspect(head(rulesSorted))
rulesRaceWhite <- subset(rules, subset = lhs %in% "race=White" & lift > 1.2)
inspect(head(rulesRaceWhite))
redundant <- is.redundant(x = rulesSorted, measure = "confidence")
rulesPruned <- rulesSorted[!redundant] # remove redundant rules
rulesPruned
inspect(head(rulesPruned))
inspect(head(rulesPruned))
mInteres <- interestMeasure(rulesPruned, measure=c("hyperConfidence", "leverage"
,"phi", "gini"), transactions=Adult)
quality(rulesPruned) <- cbind(quality(rulesPruned), mInteres)
inspect(head(sort(rulesPruned, by="phi")))
install.packages("arulesViz")
library (arulesViz)
plot(rulesPruned)
plot(rulesPruned[1:6], method="graph")
plot(rulesPruned, method="grouped")
library(colorspace)
plot(rulesPruned[1:6], method="paracoord", reorder=TRUE,
control=list(col=sequential_hcl(100)))
write(rulesPruned, file="reglas.csv", sep = ",")
install.packages("pmml")
library(pmml)
write.PMML(rulesPruned, file="reglas.pmml")
reglasPMML = read.PMML("reglas.pmml")
setwd("~/")
california <- read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", sep="", na.strings="4")
View(california)
xtra<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
head(xtra)
require(kknn)
cali<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
attach(cali)
fitknn1 <- kknn(Y ~ ., cali, cali)
cali<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
names(xtra)[n+1] <-"Y"attach(cali)
require(kknn)
cali<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
n <-length(names(cali)) -1
names(cali)[1:n] <-paste ("X", 1:n, sep="")
names(cali)[n+1] <-"Y"
attach(cali)
require(kknn)
cali<-read.csv("C:/Users/JORGE/Desktop/IntroCD/REGRESION/california.dat", comment.char="@", header = FALSE)
n <-length(names(cali)) -1
names(cali)[1:n] <-paste ("X", 1:n, sep="")
names(cali)[n+1] <-"Y"
attach(cali)
View(cali)
fitknn1 <- kknn(Y ~ ., cali, cali)
plot(Y~X4)
points(X4,fitknn1$fitted.values,col="blue",pch=20)
names(fitknn1)
fitknn1
fitknn1
test_values <- fitknn1$fitted.values
head(test_values)
test_values <- fitknn1$fitted.values
head(test_values)
yprime = fitknn1$fitted.values
sqrt(sum((cali$Y-yprime)^2)/length(yprime))
fitknn2 <- kknn(Y ~ . -X7, cali, cali)
yprime = fitknn2$fitted.values; sqrt(sum((cali$Y-yprime)^2)/length(yprime)) #RMSE
fitknn2 <- kknn(Y ~ X1+ X2 + I(X5 * X6), cali, cali)
plot(Y~X4)
points(X4,fitknn1$fitted.values,col="blue",pch=20)
points(X4,fitknn2$fitted.values,col="red",pch=20)
fitknn3 <- kknn(Y ~ X1+ X2 + I(X5 * X6), cali, cali)
yprime = fitknn3$fitted.values
sqrt(sum((cali$Y-yprime)^2)/length(yprime)) #RMSE
fitprueba=lm(Y~X4 +X6 +I(X4 * X6) +I(X4^2) +I(X4^2 * X6),cali)
y_knn <- fitknn1$fitted.values
sqrt(sum((cali$Y - y_knn)^2) / length(y_knn))
y_lm <- fitprueba$fitted.values
sqrt(sum((cali$Y - y_lm)^2) / length(y_lm))
nombre <- "s"
run_lm_fold <- function(i, x = "california", tt = "test") {
file <- paste(x, "-5-", i, "tra.dat", sep="")
x_tra <- read.csv(file, comment.char="@", header=FALSE)
file <- paste(x, "-5-", i, "tst.dat", sep="")
x_tst <- read.csv(file, comment.char="@", header=FALSE)
In <- length(names(x_tra)) - 1
names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
names(x_tra)[In+1] <- "Y"
names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
names(x_tst)[In+1] <- "Y"
if (tt == "train") {
test <- x_tra
}
else {
test <- x_tst
}
fitMulti=lm(Y~.,x_tra)
yprime=predict(fitMulti,test)
sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train"))
lmMSEtest<-mean(sapply(1:5,run_lm_fold,nombre,"test"))
#------------- 5-fold cross-validation LM todas las variables
nombre <- "california"
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train"))
#------------- 5-fold cross-validation LM todas las variables
nombre <- "C:/Users/JORGE/Desktop/IntroCD/REGRESION/california"
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train"))
lmMSEtest<-mean(sapply(1:5,run_lm_fold,nombre,"test"))
#------------- 5-fold cross-validation KNN todas las variables
nombre <- "C:/Users/JORGE/Desktop/IntroCD/REGRESION/california"
run_knn_fold <- function(i, x, tt = "test") {
file <- paste(x, "-5-", i, "tra.dat", sep="")
x_tra <- read.csv(file, comment.char="@", header=FALSE)
file <- paste(x, "-5-", i, "tst.dat", sep="")
x_tst <- read.csv(file, comment.char="@", header=FALSE)
In <- length(names(x_tra)) - 1
names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
names(x_tra)[In+1] <- "Y"
names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
names(x_tst)[In+1] <- "Y"
if (tt == "train") {
test <- x_tra
}
else {
test <- x_tst
}
fitMulti=kknn(Y~.,x_tra,test)
yprime=fitMulti$fitted.values
sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
knnMSEtrain<-mean(sapply(1:5,run_knn_fold,nombre,"train"))
knnMSEtest<-mean(sapply(1:5,run_knn_fold,nombre,"test"))
resultados <- read.csv("regr_test_alumnos.csv")
tablatst <- cbind(resultados[,2:dim(resultados)[2]])
colnames(tablatst) <- names(resultados)[2:dim(resultados)[2]]
rownames(tablatst) <- resultados[,1]
lmMSEtrain
knnMSEtrain
lmMSEtest
knnMSEtest
reticulate::repl_python()
# %%
from os import accessy
from IPython.core.interactiveshell import InteractiveShell
from numpy import int64
reticulate::install_miniconda()
py_config()
reticulate::repl_python()
import os
import cv2
import numpy as np
num.vecinos.lof = 3
lof.scores = LOF(set_train[,c(1:20)], k = num.vecinos.lof)
length(lof.scores)
lof.scores = cbind(lof.scores, 1:length(lof.scores))
#lo ordeno con las etiquetas para facilitar los pasos siguientes
lof.scores.ordenados = lof.scores[order(lof.scores[,1], decreasing = T),]
plot(lof.scores.ordenados[,1])
length(lof.scores)
library(ggplot2)
library(ggplot2)
library(tidyverse)
library(fitdistrplus)  # Ajuste de una distribución -> denscomp
library(reshape)   # melt
library(ggbiplot)  # biplot
library(outliers)  # Grubbs
library(MVN)       # mvn: Test de normalidad multivariante
library(CerioliOutlierDetection)  #MCD Hardin Rocke
library(mvoutlier) # corr.plot
library(DDoutlier) # lof
library(cluster)   # PAM
datos <- as.data.frame(read_csv('training_set_featuresA.csv'))
setwd("~/GitHub/TRABAJO/scripts/CART")
datos <- as.data.frame(read_csv('training_set_featuresA.csv'))
dat_lab <- as.data.frame(read_csv('training_set_labels.csv'))
df = merge(datos,dat_lab)
df$respondent_id = NULL
df_encoded = df
df_encoded$sex = factor(df$sex, labels=c(0,1)) #Female 0,  #Male 1
df_encoded$marital_status = factor(df$marital_status, labels=c(0,1)) #Not Married 0, #Married 1
df_encoded$rent_or_own = factor(df$rent_or_own, labels=c(0,1)) #Own 0, #Rent 1
df_encoded$education = factor(df$education, levels=c("< 12 Years", "12 Years", "Some College", "College Graduate"), labels=c(1:4), ordered=TRUE)
df_encoded$age_group = factor(df$age_group, levels=c("18 - 34 Years","35 - 44 Years","45 - 54 Years","55 - 64 Years","65+ Years"), labels=c(1:5), ordered=TRUE)
df_encoded$income_poverty = factor(df$income_poverty, levels=c("Below Poverty","<= $75,000, Above Poverty","> $75,000" ), labels=c(1:3), ordered=TRUE)
label_encoding = function(x){factor(x, labels=c(1:length(unique(na.omit(x)))))}
df_encoded$race = label_encoding(df$race)
df_encoded$employment_status = label_encoding(df$employment_status)
df_encoded$hhs_geo_region = label_encoding(df$hhs_geo_region)
df_encoded$census_msa = label_encoding(df$census_msa)
df_encoded$employment_industry = label_encoding(df$employment_industry)
df_encoded$employment_occupation = label_encoding(df$employment_occupation)
boxplot(df_encoded[,c(1:22)])
outlier_values <- boxplot.stats(df_encoded[,c(1:19)])$out  # outlier values.
library(MVN)
library(CerioliOutlierDetection)
test.MVN = mvn(df_encoded[,c(2:3)], mvnTest = "energy")
test.MVN$multivariateNormality["MVN"]
set_train = df_encoded
set_train = drop_na(set_train)
set.seed(2)
num.vecinos.lof = 3
lof.scores = LOF(set_train[,c(1:20)], k = num.vecinos.lof)
length(lof.scores)
lof.scores = cbind(lof.scores, 1:length(lof.scores))
#lo ordeno con las etiquetas para facilitar los pasos siguientes
lof.scores.ordenados = lof.scores[order(lof.scores[,1], decreasing = T),]
plot(lof.scores.ordenados[,1])
num.vecinos.lof = 7
lof.scores = LOF(set_train[,c(1:20)], k = num.vecinos.lof)
length(lof.scores)
lof.scores = cbind(lof.scores, 1:length(lof.scores))
#lo ordeno con las etiquetas para facilitar los pasos siguientes
lof.scores.ordenados = lof.scores[order(lof.scores[,1], decreasing = T),]
plot(lof.scores.ordenados[,1])
num.vecinos.lof = 5
lof.scores = LOF(set_train[,c(1:20)], k = num.vecinos.lof)
length(lof.scores)
lof.scores = cbind(lof.scores, 1:length(lof.scores))
#lo ordeno con las etiquetas para facilitar los pasos siguientes
lof.scores.ordenados = lof.scores[order(lof.scores[,1], decreasing = T),]
plot(lof.scores.ordenados[,1])
num.vecinos.lof = 11
lof.scores = LOF(set_train[,c(1:20)], k = num.vecinos.lof)
length(lof.scores)
lof.scores = cbind(lof.scores, 1:length(lof.scores))
#lo ordeno con las etiquetas para facilitar los pasos siguientes
lof.scores.ordenados = lof.scores[order(lof.scores[,1], decreasing = T),]
plot(lof.scores.ordenados[,1])
num.vecinos.lof = 5
View(lof.scores.ordenados)
View(lof.scores)
